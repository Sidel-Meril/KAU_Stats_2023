{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488dd4f0",
   "metadata": {},
   "source": [
    "# Problem\n",
    "* Choose any dataset for multiclass classification on [Kaggle](https://www.kaggle.com/) (go to \"Datasets\" section, choose \"Filter\" and enter \"multiclass classification\" into the \"Tags\" field). \n",
    "* Perform classification with few methods. I expect you to use at least SVM (linear and rbf) and random forest.\n",
    "* Try getting the best result with each of the methods. I expect you to use at least GridSearch for hyperparameters tuning.\n",
    "* Try feature engineering. I expect you to use at least PCA for dimensionality reduction.\n",
    "* Calculate accuracy and confusion matrix for each of the methods.\n",
    "* Draw conclusions. Which method is the best? Why? If the dataset has any articles linked, compare your results with the state of the art.\n",
    "\n",
    "# Grading criteria:\n",
    "* I expect a confident usage of sklearn methods.\n",
    "* I expect understanding of basics of models assessment.\n",
    "* I expect you to be able to learn PCA method on your own.\n",
    "* I expect the ability of succinct, cohesive, and coherent expression of your thoughts, i.e. clearly state (in a few sentences) what is the problem you are solving, what approaches do you propose, and what conclusions can be drawn regarding these approaches in the context of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305869ba",
   "metadata": {},
   "source": [
    "Machine Learning problem solving includes several steps:\n",
    "+ Training\n",
    "+ Evaluation\n",
    "+ Analysis\n",
    "\n",
    "The steps accompany each choosed method for evaluation and choosing the right solution. \n",
    "\n",
    "In general the next structure is defined for overall solution\n",
    "+ Data exploration\n",
    "+ Feature engineering \n",
    "+ Selection of metrics\n",
    "+ Choosing models\n",
    "+ Train/Validation/Hyperparameter tuning\n",
    "+ Comparsion and choosing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opendatasets\n",
    "from IPython.display import Markdown as md\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np, re\n",
    "import scipy.stats as sts\n",
    "import seaborn as sns\n",
    "import os, opendatasets as od"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291b7ea0",
   "metadata": {},
   "source": [
    "# Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9797572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# od.download(\"https://www.kaggle.com/datasets/zalando-research/fashionmnist\")\n",
    "os.listdir('./fashionmnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73bd8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = pd.read_csv('./fashionmnist/fashion-mnist_train.csv'), pd.read_csv('./fashionmnist/fashion-mnist_test.csv')\n",
    "print(df_train.info(), df_test.info())\n",
    "print(df_train.describe(), df_test.describe())\n",
    "print(df_train.head(), df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fe7718",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd20861",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w, img_h = 28, 28\n",
    "_xcol = ['pixel'+str(i+1) for i in range(28*28)]\n",
    "_ycol = ['label']\n",
    "x_train, x_test, y_train, y_test = df_train[_xcol].to_numpy(),  df_test[_xcol].to_numpy(), df_train[_ycol].to_numpy(), df_test[_ycol].to_numpy() \n",
    "print('Train:', x_train.shape, y_train.shape)\n",
    "print('Test:', x_test.shape, y_test.shape)\n",
    "print('Train classes:', np.unique(y_train))\n",
    "print('Test classes:', np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01359c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize = (6,4))\n",
    "names, counts = np.unique(y_train, return_counts=True)\n",
    "ax[0].bar(names, counts)\n",
    "ax[0].set_title('Train')\n",
    "ax[0].set_xticks(names)\n",
    "ax[0].set_ylabel('Counts')\n",
    "ax[0].set_xlabel('Label')\n",
    "names, counts = np.unique(y_test, return_counts=True)\n",
    "ax[1].bar(names,counts)\n",
    "ax[1].set_title('Test')\n",
    "ax[1].set_xticks(names)\n",
    "ax[1].set_ylabel('Counts')\n",
    "ax[1].set_xlabel('Label')\n",
    "fig.suptitle('Classes distribution')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots (nrows = 2, ncols = 5, figsize = (6,4))\n",
    "ax = ax.flatten()\n",
    "for i, iax in enumerate(ax):\n",
    "    sample, label = x_train[y_train.flatten()==i][0], i\n",
    "    iax.imshow(sample.reshape(img_h, img_w), cmap='binary')\n",
    "    iax.set_xlabel(label)\n",
    "    iax.set_xticks([])\n",
    "    iax.set_yticks([])\n",
    "fig.suptitle('Test data')\n",
    "plt.tight_layout()\n",
    "\n",
    "fig, ax = plt.subplots (nrows = 2, ncols = 5, figsize = (6,4))\n",
    "ax = ax.flatten()\n",
    "for i, iax in enumerate(ax):\n",
    "    sample, label = x_test[y_test.flatten()==i][0], i\n",
    "    iax.imshow(sample.reshape(img_h, img_w), cmap='binary')\n",
    "    iax.set_xlabel(label)\n",
    "    iax.set_xticks([])\n",
    "    iax.set_yticks([])\n",
    "fig.suptitle('Train data')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27024e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(x_train, axis=0)\n",
    "std = np.std(x_train, axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "ax[0].imshow(mean.astype(np.uint8).reshape(img_w,img_h), cmap='binary')\n",
    "ax[1].imshow(std.astype(np.uint8).reshape(img_w,img_h), cmap='binary')\n",
    "ax[0].set_title(\"Mean\")\n",
    "ax[1].set_title(\"Standard deviation\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e777e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "px_means=[]\n",
    "px_stds=[]\n",
    "for label in range(10):\n",
    "    label_data = x_train[y_train.flatten()==label]\n",
    "    mean = np.mean(label_data, axis=0)\n",
    "    std = np.std(label_data, axis=0)\n",
    "    px_means.append(mean)\n",
    "    px_stds.append(std)\n",
    "    \n",
    "fig, ax = plt.subplots (nrows = 2, ncols = 5, figsize = (10,5))\n",
    "ax = ax.flatten()\n",
    "for i, iax in enumerate(ax):\n",
    "    iax.imshow(px_means[i].astype(np.uint8).reshape(img_w,img_h), cmap='binary')\n",
    "    iax.set_xlabel(i)\n",
    "fig.suptitle('Means by labels')\n",
    "plt.tight_layout()\n",
    "\n",
    "fig, ax = plt.subplots (nrows = 2, ncols = 5, figsize = (10,5))\n",
    "ax = ax.flatten()\n",
    "for i, iax in enumerate(ax):\n",
    "    iax.imshow(px_stds[i].astype(np.uint8).reshape(img_w,img_h), cmap='binary')\n",
    "    iax.set_xlabel(i)\n",
    "fig.suptitle('Standart deviation by labels')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c313c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "# Compute the two-dimensional Fourier transform of an image and visualize its power spectrum\n",
    "\n",
    "num_examples = 3\n",
    "fig, ax = plt.subplots(nrows=10, ncols=num_examples*2, figsize=(10, 20))\n",
    "\n",
    "for iclass in range(10):\n",
    "    img_idxs = np.where(y_train.flatten()==iclass)[0]\n",
    "\n",
    "    for j,i in enumerate(img_idxs[:num_examples]):\n",
    "        img_fft = fftpack.fft2(x_train[i].reshape(img_w, img_h))\n",
    "        img_fft_shift = fftpack.fftshift(img_fft)\n",
    "        power_spectrum = np.abs(img_fft_shift) ** 2\n",
    "\n",
    "        ax[iclass][j*2].imshow(x_train[i].reshape(img_w, img_h), cmap='binary')\n",
    "        ax[iclass][j*2+1].imshow(np.log10(power_spectrum), cmap='gray')\n",
    "        ax[iclass][3].set_title(str(iclass))\n",
    "        ax[iclass][j*2].axis('off')\n",
    "        ax[iclass][j*2+1].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f3331",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4100f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "#Normalize\n",
    "_norm = Normalizer()\n",
    "x_train = _norm.fit_transform(x_train)\n",
    "x_test = _norm.transform(x_test)\n",
    "print(x_train.min(), x_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebbe741",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots (nrows = 2, ncols = 5, figsize = (6,4))\n",
    "ax = ax.flatten()\n",
    "for i, iax in enumerate(ax):\n",
    "    sample, label = x_train[y_train.flatten()==i][0], i\n",
    "    iax.imshow(sample.reshape(img_h, img_w), cmap='binary')\n",
    "    iax.set_xlabel(label)\n",
    "    iax.set_xticks([])\n",
    "    iax.set_yticks([])\n",
    "fig.suptitle('Normalized data')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc22f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA().fit(x_train)\n",
    "plt.grid()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance')\n",
    "\n",
    "quantiles = np.arange(0.25, 0.75, 0.1)\n",
    "n_components = np.zeros(len(quantiles))\n",
    "for i, quantile in enumerate(quantiles):\n",
    "    n_components[i] = np.where(pca.explained_variance_ratio_<np.quantile(pca.explained_variance_ratio_, quantile))[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfdb110",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = np.random.randint(len(x_train))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=len(n_components), ncols=3, figsize=(5,8))\n",
    "\n",
    "for i in range(len(n_components)):\n",
    "    in_components = n_components[i]\n",
    "    \n",
    "    pca= PCA(int(in_components)).fit(x_train)\n",
    "    transformed_ = pca.transform(x_train[test_sample].reshape(1,-1))\n",
    "    restored_ = pca.inverse_transform(transformed_)\n",
    "    restored_ = np.clip(restored_, 0, 1)\n",
    "    print(restored_.min(), restored_.max())\n",
    "    print(transformed_.shape)\n",
    "    print(f'Explained variance for n_components = {in_components}:', np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "    ax[i][0].imshow(x_train[test_sample].reshape(img_w, img_h), cmap='binary')\n",
    "    ax[i][0].axis('off')\n",
    "\n",
    "    ax[i][1].imshow(restored_.reshape(img_w, img_h), cmap='binary')\n",
    "    ax[i][1].axis('off')\n",
    "    ax[i][1].set_title(f'Original/Restored/Difference of sample {test_sample} for n_components = {in_components}')\n",
    "\n",
    "    ax[i][2].imshow(np.clip(x_train[test_sample]-restored_, 0, 1).reshape(img_w, img_h), cmap='binary')\n",
    "    ax[i][2].axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac384770",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf9fe34",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928679de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def print_evaluate(y_test, y_pred):\n",
    "    #confussion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # metrics\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "#     precission = precision_score(y_test,y_pred)\n",
    "#     recall = recall_score(y_test,y_pred)\n",
    "#     print('Precision', precission)\n",
    "#     print('Recall', recall)\n",
    "    print('Accuracy', accuracy)\n",
    "\n",
    "    sns.heatmap(cm, annot=True, cmap='coolwarm', fmt='.3g')\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e708576",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c677de",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5837a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "kernels = ['rbf', 'sigmoid','linear']\n",
    "\n",
    "param_grid = {\n",
    "'kernel': kernels,\n",
    "# 'C': [0.1, 1, 10, 100],\n",
    "# 'gamma': ['scale', 'auto'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train.ravel())\n",
    "print(f'best param.:', grid_search.best_params_)\n",
    "\n",
    "final_model_svc = SVC(**grid_search.best_params_)\n",
    "final_model_svc.fit(x_train, y_train.ravel())\n",
    "y_pred = final_model_svc.predict(x_test)\n",
    "\n",
    "print_evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd19f46",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f59c2",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu2)",
   "language": "python",
   "name": "tf_gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
